{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC490 Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K19HB997HXF2",
        "outputId": "9edb24a5-8860-4277-e8b9-5fa07da48d68"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "MOUNTPOINT = '/content/gdrive'\n",
        "drive.mount(MOUNTPOINT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Y9Z7xEIaeS"
      },
      "source": [
        "!pip install numpy scipy torch nibabel simpleITK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MryzevwUIjP5",
        "outputId": "b7f7ba3b-9fb5-4d66-ef7a-7dc566d5070c"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/brats17\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/brats17\n",
            "/content/gdrive/MyDrive/brats17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvOhFH22IwBs"
      },
      "source": [
        "!python util/evaluation.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4yMcXC_Q0Bq"
      },
      "source": [
        "!rm -rf result17\n",
        "!mkdir result17\n",
        "!mkdir result17/HGG\n",
        "!mkdir result17/LGG"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWt88sJBYtQE"
      },
      "source": [
        "from util.train_test_func import *"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ag1ZaQWQj06",
        "outputId": "bd749e74-6f63-4a1d-f72c-abec4db5bf91"
      },
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "# import tensorflow as tf\n",
        "import torch\n",
        "# from tensorflow.contrib.data import Iterator\n",
        "from util.data_loader import *\n",
        "from util.data_process import *\n",
        "from util.parse_config import parse_config\n",
        "from util.train_test_func import *\n",
        "from util.MSNet import MSNet\n",
        "class NetFactory(object):\n",
        "    @staticmethod\n",
        "    def create(name):\n",
        "        if name == 'MSNet':\n",
        "            return MSNet\n",
        "        # add your own networks here\n",
        "        print('unsupported network:', name)\n",
        "        exit()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config_file = './config17/test_wt.txt'\n",
        "# 1, load configure file\n",
        "config = parse_config(config_file)\n",
        "config_data = config['data']\n",
        "config_net1 = config.get('network1', None)\n",
        "config_net2 = config.get('network2', None)\n",
        "config_net3 = config.get('network3', None)\n",
        "config_test = config['testing']\n",
        "batch_size = config_test.get('batch_size', 5)\n",
        "\n",
        "# 2.1, network for whole tumor\n",
        "if (config_net1):\n",
        "    net_type1 = config_net1['net_type']\n",
        "    net_name1 = config_net1['net_name']\n",
        "    data_shape1 = config_net1['data_shape']\n",
        "    label_shape1 = config_net1['label_shape']\n",
        "    class_num1 = config_net1['class_num']\n",
        "    model_save_prefix1 = config_net1['model_save_prefix'] + \".pt\"\n",
        "\n",
        "    # construct graph for 1st network\n",
        "    full_data_shape1 = [batch_size] + data_shape1\n",
        "    \n",
        "    # x1 = tf.placeholder(tf.float32, shape = full_data_shape1) \n",
        "    # x1 = torch.zeros(full_data_shape1, dtype=torch.float32, requires_grad=True)\n",
        "    net_class1 = NetFactory.create(net_type1)\n",
        "    net1 = net_class1(num_classes=class_num1, w_reg=None,\n",
        "                      b_reg=None, in_chns=full_data_shape1[-1])\n",
        "    # net1.set_params(config_net1)\n",
        "    net1.load_state_dict(torch.load(model_save_prefix1, map_location=device)[\"model_state_dict\"])\n",
        "else:\n",
        "    config_net1ax = config['network1ax']\n",
        "    config_net1sg = config['network1sg']\n",
        "    config_net1cr = config['network1cr']\n",
        "\n",
        "    # construct graph for 1st network axial\n",
        "    net_type1ax = config_net1ax['net_type']\n",
        "    net_name1ax = config_net1ax['net_name']\n",
        "    data_shape1ax = config_net1ax['data_shape']\n",
        "    label_shape1ax = config_net1ax['label_shape']\n",
        "    class_num1ax = config_net1ax['class_num']\n",
        "    model_save_prefix1ax = config_net1ax['model_save_prefix'] + \".pt\"\n",
        "\n",
        "    full_data_shape1ax = [batch_size] + data_shape1ax\n",
        "    # x1ax = tf.placeholder(tf.float32, shape = full_data_shape1ax)\n",
        "    # x1ax = torch.zeros(full_data_shape1ax, dtype=torch.float32, requires_grad=True)\n",
        "    net_class1ax = NetFactory.create(net_type1ax)\n",
        "    net1ax = net_class1ax(num_classes=class_num1ax, w_reg=None,\n",
        "                          b_reg=None, in_chns=full_data_shape1ax[-1])\n",
        "    # net1ax.set_params(config_net1ax)\n",
        "    net1ax.load_state_dict(torch.load(model_save_prefix1ax, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "    # construct graph for 1st network sagittal\n",
        "    net_type1sg = config_net1sg['net_type']\n",
        "    net_name1sg = config_net1sg['net_name']\n",
        "    data_shape1sg = config_net1sg['data_shape']\n",
        "    label_shape1sg = config_net1sg['label_shape']\n",
        "    class_num1sg = config_net1sg['class_num']\n",
        "    model_save_prefix1sg = config_net1sg['model_save_prefix'] + \".pt\"\n",
        "\n",
        "    full_data_shape1sg = [batch_size] + data_shape1sg\n",
        "    # x1sg = tf.placeholder(tf.float32, shape = full_data_shape1sg)\n",
        "    # x1sg = torch.zeros(full_data_shape1sg, dtype=torch.float32, requires_grad=True)\n",
        "    net_class1sg = NetFactory.create(net_type1sg)\n",
        "    net1sg = net_class1sg(num_classes=class_num1sg, w_reg=None,\n",
        "                          b_reg=None, in_chns=full_data_shape1sg[-1])\n",
        "    # net1sg.set_params(config_net1sg)\n",
        "    net1sg.load_state_dict(torch.load(model_save_prefix1sg, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "    # construct graph for 1st network corogal\n",
        "    net_type1cr = config_net1cr['net_type']\n",
        "    net_name1cr = config_net1cr['net_name']\n",
        "    data_shape1cr = config_net1cr['data_shape']\n",
        "    label_shape1cr = config_net1cr['label_shape']\n",
        "    class_num1cr = config_net1cr['class_num']\n",
        "    model_save_prefix1cr = config_net1cr['model_save_prefix'] + \".pt\"\n",
        "\n",
        "    full_data_shape1cr = [batch_size] + data_shape1cr\n",
        "    # x1cr = tf.placeholder(tf.float32, shape = full_data_shape1cr)\n",
        "    # x1cr = torch.zeros(full_data_shape1cr, dtype=torch.float32, requires_grad=True)\n",
        "    net_class1cr = NetFactory.create(net_type1cr)\n",
        "    net1cr = net_class1cr(num_classes=class_num1cr, w_reg=None,\n",
        "                          b_reg=None, in_chns=full_data_shape1cr[-1])\n",
        "    # net1cr.set_params(config_net1cr)\n",
        "    net1cr.load_state_dict(torch.load(model_save_prefix1cr, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "if (config_test.get('whole_tumor_only', False) is False):\n",
        "    # 2.2, networks for tumor core\n",
        "    if (config_net2):\n",
        "        net_type2 = config_net2['net_type']\n",
        "        net_name2 = config_net2['net_name']\n",
        "        data_shape2 = config_net2['data_shape']\n",
        "        label_shape2 = config_net2['label_shape']\n",
        "        class_num2 = config_net2['class_num']\n",
        "        model_save_prefix2 = config_net2['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        # construct graph for 2st network\n",
        "        full_data_shape2 = [batch_size] + data_shape2\n",
        "        # x2 = tf.placeholder(tf.float32, shape = full_data_shape2)\n",
        "        # x2 = torch.zeros(full_data_shape2, dtype=torch.float32, requires_grad=True)\n",
        "        net_class2 = NetFactory.create(net_type2)\n",
        "        net2 = net_class2(num_classes=class_num2, w_reg=None,\n",
        "                          b_reg=None, in_chns=full_data_shape2[-1])\n",
        "        # net2.set_params(config_net2)\n",
        "        net2.load_state_dict(torch.load(model_save_prefix2, map_location=device)[\"model_state_dict\"])\n",
        "    else:\n",
        "        config_net2ax = config['network2ax']\n",
        "        config_net2sg = config['network2sg']\n",
        "        config_net2cr = config['network2cr']\n",
        "\n",
        "        # construct graph for 2st network axial\n",
        "        net_type2ax = config_net2ax['net_type']\n",
        "        net_name2ax = config_net2ax['net_name']\n",
        "        data_shape2ax = config_net2ax['data_shape']\n",
        "        label_shape2ax = config_net2ax['label_shape']\n",
        "        class_num2ax = config_net2ax['class_num']\n",
        "        model_save_prefix2ax = config_net2ax['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape2ax = [batch_size] + data_shape2ax\n",
        "        # x2ax = tf.placeholder(tf.float32, shape = full_data_shape2ax)\n",
        "        # x2ax = torch.zeros(full_data_shape2ax, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        net_class2ax = NetFactory.create(net_type2ax)\n",
        "        net2ax = net_class2ax(num_classes=class_num2ax, w_reg=None,\n",
        "                              b_reg=None, in_chns=full_data_shape2ax[-1])\n",
        "        # net2ax.set_params(config_net2ax)\n",
        "        net2ax.load_state_dict(torch.load(model_save_prefix2ax, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "        # construct graph for 2st network sagittal\n",
        "        net_type2sg = config_net2sg['net_type']\n",
        "        net_name2sg = config_net2sg['net_name']\n",
        "        data_shape2sg = config_net2sg['data_shape']\n",
        "        label_shape2sg = config_net2sg['label_shape']\n",
        "        class_num2sg = config_net2sg['class_num']\n",
        "        model_save_prefix2sg = config_net2sg['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape2sg = [batch_size] + data_shape2sg\n",
        "        # x2sg = tf.placeholder(tf.float32, shape = full_data_shape2sg)\n",
        "        # x2sg = torch.zeros(full_data_shape2sg, dtype=torch.float32, requires_grad=True)\n",
        "        net_class2sg = NetFactory.create(net_type2sg)\n",
        "        net2sg = net_class2sg(num_classes=class_num2sg, w_reg=None,\n",
        "                              b_reg=None, in_chns=full_data_shape2sg[-1])\n",
        "        # net2sg.set_params(config_net2sg)\n",
        "        net2sg.load_state_dict(torch.load(model_save_prefix2sg, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "        # construct graph for 2st network corogal\n",
        "        net_type2cr = config_net2cr['net_type']\n",
        "        net_name2cr = config_net2cr['net_name']\n",
        "        data_shape2cr = config_net2cr['data_shape']\n",
        "        label_shape2cr = config_net2cr['label_shape']\n",
        "        class_num2cr = config_net2cr['class_num']\n",
        "        model_save_prefix2cr = config_net2cr['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape2cr = [batch_size] + data_shape2cr\n",
        "        # x2cr = tf.placeholder(tf.float32, shape = full_data_shape2cr)\n",
        "        # x2cr = torch.zeros(full_data_shape2cr, dtype=torch.float32, requires_grad=True)\n",
        "        net_class2cr = NetFactory.create(net_type2cr)\n",
        "        net2cr = net_class2cr(num_classes=class_num2cr, w_reg=None,\n",
        "                              b_reg=None, in_chns=full_data_shape2cr[-1])\n",
        "        # net2cr.set_params(config_net2cr)\n",
        "        net2cr.load_state_dict(torch.load(model_save_prefix2cr, map_location=device)[\"model_state_dict\"])\n",
        "        \n",
        "\n",
        "    # 2.3, networks for enhanced tumor\n",
        "    if (config_net3):\n",
        "        net_type3 = config_net3['net_type']\n",
        "        net_name3 = config_net3['net_name']\n",
        "        data_shape3 = config_net3['data_shape']\n",
        "        label_shape3 = config_net3['label_shape']\n",
        "        class_num3 = config_net3['class_num']\n",
        "        model_save_prefix3 = config_net3['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        # construct graph for 3st network\n",
        "        full_data_shape3 = [batch_size] + data_shape3\n",
        "        # x3 = tf.placeholder(tf.float32, shape = full_data_shape3)\n",
        "        # x3 = torch.zeros(full_data_shape3, dtype=torch.float32, requires_grad=True)\n",
        "        net_class3 = NetFactory.create(net_type3)\n",
        "        net3 = net_class3(num_classes=class_num3, w_reg=None,b_reg=None, in_chns=full_data_shape3[-1])\n",
        "        # net3.set_params(config_net3)\n",
        "        net3.load_state_dict(torch.load(model_save_prefix3, map_location=device)[\"model_state_dict\"])\n",
        "    else:\n",
        "        config_net3ax = config['network3ax']\n",
        "        config_net3sg = config['network3sg']\n",
        "        config_net3cr = config['network3cr']\n",
        "\n",
        "        # construct graph for 3st network axial\n",
        "        net_type3ax = config_net3ax['net_type']\n",
        "        net_name3ax = config_net3ax['net_name']\n",
        "        data_shape3ax = config_net3ax['data_shape']\n",
        "        label_shape3ax = config_net3ax['label_shape']\n",
        "        class_num3ax = config_net3ax['class_num']\n",
        "        model_save_prefix3ax = config_net3ax['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape3ax = [batch_size] + data_shape3ax\n",
        "        # x3ax = tf.placeholder(tf.float32, shape = full_data_shape3ax)\n",
        "        # x3ax = torch.zeros(full_data_shape3ax, dtype=torch.float32, requires_grad=True)\n",
        "        net_class3ax = NetFactory.create(net_type3ax)\n",
        "        net3ax = net_class3ax(num_classes=class_num3ax, w_reg=None,\n",
        "                              b_reg=None, in_chns=full_data_shape3ax[-1])\n",
        "        # net3ax.set_params(config_net3ax)\n",
        "        net3ax.load_state_dict(torch.load(model_save_prefix3ax, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "        # construct graph for 3st network sagittal\n",
        "        net_type3sg = config_net3sg['net_type']\n",
        "        net_name3sg = config_net3sg['net_name']\n",
        "        data_shape3sg = config_net3sg['data_shape']\n",
        "        label_shape3sg = config_net3sg['label_shape']\n",
        "        class_num3sg = config_net3sg['class_num']\n",
        "        model_save_prefix3sg = config_net3sg['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        # construct graph for 3st network\n",
        "        full_data_shape3sg = [batch_size] + data_shape3sg\n",
        "        # x3sg = tf.placeholder(tf.float32, shape = full_data_shape3sg)\n",
        "        # x3sg = torch.zeros(full_data_shape3sg, dtype=torch.float32, requires_grad=True)\n",
        "        net_class3sg = NetFactory.create(net_type3sg)\n",
        "        net3sg = net_class3sg(num_classes=class_num3sg, w_reg=None,\n",
        "                              b_reg=None, in_chns=full_data_shape3sg[-1])\n",
        "        # net3sg.set_params(config_net3sg)\n",
        "        net3sg.load_state_dict(torch.load(model_save_prefix3sg, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "        # construct graph for 3st network corogal\n",
        "        net_type3cr = config_net3cr['net_type']\n",
        "        net_name3cr = config_net3cr['net_name']\n",
        "        data_shape3cr = config_net3cr['data_shape']\n",
        "        label_shape3cr = config_net3cr['label_shape']\n",
        "        class_num3cr = config_net3cr['class_num']\n",
        "        model_save_prefix3cr = config_net3cr['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        # construct graph for 3st network\n",
        "        full_data_shape3cr = [batch_size] + data_shape3cr\n",
        "        # x3cr = tf.placeholder(tf.float32, shape = full_data_shape3cr)\n",
        "        # x3cr = torch.zeros(full_data_shape3cr, dtype=torch.float32, requires_grad=True)\n",
        "        net_class3cr = NetFactory.create(net_type3cr)\n",
        "        net3cr = net_class3cr(num_classes=class_num3cr, w_reg=None,\n",
        "                              b_reg=None, in_chns=full_data_shape3cr[-1])\n",
        "        # net3cr.set_params(config_net3cr)\n",
        "        net3cr.load_state_dict(torch.load(model_save_prefix3cr, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "import os\n",
        "print(os.curdir)\n",
        "dataloader = DataLoader(config_data)\n",
        "dataloader.load_data()\n",
        "image_num = dataloader.get_total_image_number()\n",
        "\n",
        "# 5, start to test\n",
        "test_slice_direction = config_test.get('test_slice_direction', 'all')\n",
        "save_folder = config_data['save_folder']\n",
        "test_time = []\n",
        "struct = ndimage.generate_binary_structure(3, 2)\n",
        "margin = config_test.get('roi_patch_margin', 5)\n",
        "print(\"image_num\",image_num)\n",
        "\n",
        "for i in range(image_num):\n",
        "    [temp_imgs, temp_weight, temp_name, img_names, temp_bbox, temp_size] = dataloader.get_image_data_with_name(i)\n",
        "    t0 = time.time()\n",
        "# 5.1, test of 1st network\n",
        "    data_shape = None\n",
        "    if (config_net1):\n",
        "        data_shapes = [data_shape1[:-1], data_shape1[:-1], data_shape1[:-1]]\n",
        "        data_shape = data_shape1\n",
        "        label_shapes = [label_shape1[:-1], label_shape1[:-1], label_shape1[:-1]]\n",
        "        nets = [net1, net1, net1]\n",
        "        #inputs = [x1, x1, x1]\n",
        "        class_num = class_num1\n",
        "    else:\n",
        "        data_shapes = [data_shape1ax[:-1], data_shape1sg[:-1], data_shape1cr[:-1]]\n",
        "        data_shape = data_shape1ax[-1]\n",
        "        label_shapes = [label_shape1ax[:-1], label_shape1sg[:-1], label_shape1cr[:-1]]\n",
        "        nets = [net1ax, net1sg, net1cr]\n",
        "        #inputs = [x1ax, x1sg, x1cr]\n",
        "        class_num = class_num1ax\n",
        "    for i in range(len(nets)):\n",
        "        nets[i] = nets[i].to(device)\n",
        "    # print('=' * 20, \"Going to prediction\")\n",
        "    prob1 = test_one_image_three_nets_adaptive_shape(temp_imgs, data_shapes, label_shapes, data_shape[-1],\n",
        "                                                     class_num,\n",
        "                                                     batch_size, nets, 2)\n",
        "    pred1 = np.asarray(np.argmax(prob1, axis=3), np.uint16)\n",
        "    pred1 = pred1 * temp_weight\n",
        "    \n",
        "    # print(pred1.shape)\n",
        "    wt_threshold = 2000\n",
        "    if (config_test.get('whole_tumor_only', False) is True):\n",
        "        pred1_lc = ndimage.morphology.binary_closing(pred1, structure=struct)\n",
        "        pred1_lc = get_largest_two_component(pred1_lc, False, wt_threshold)\n",
        "        out_label = pred1_lc\n",
        "    else:\n",
        "        # 5.2, test of 2nd network\n",
        "        if (pred1.sum() == 0):\n",
        "            print('net1 output is null', temp_name)\n",
        "            bbox1 = get_ND_bounding_box(temp_imgs[0] > 0, margin)\n",
        "        else:\n",
        "            pred1_lc = ndimage.morphology.binary_closing(pred1, structure=struct)\n",
        "            pred1_lc = get_largest_two_component(pred1_lc, False, wt_threshold)\n",
        "            bbox1 = get_ND_bounding_box(pred1_lc, margin)\n",
        "        sub_imgs = [crop_ND_volume_with_bounding_box(one_img, bbox1[0], bbox1[1]) for one_img in temp_imgs]\n",
        "        sub_weight = crop_ND_volume_with_bounding_box(temp_weight, bbox1[0], bbox1[1])\n",
        "    \n",
        "        if (config_net2):\n",
        "            data_shapes = [data_shape2[:-1], data_shape2[:-1], data_shape2[:-1]]\n",
        "            label_shapes = [label_shape2[:-1], label_shape2[:-1], label_shape2[:-1]]\n",
        "            nets = [net2, net2, net2]\n",
        "            #inputs = [x2, x2, x2]\n",
        "            class_num = class_num2\n",
        "        else:\n",
        "            data_shapes = [data_shape2ax[:-1], data_shape2sg[:-1], data_shape2cr[:-1]]\n",
        "            label_shapes = [label_shape2ax[:-1], label_shape2sg[:-1], label_shape2cr[:-1]]\n",
        "            nets = [net2ax, net2sg, net2cr]\n",
        "            #inputs = [x2ax, x2sg, x2cr]\n",
        "            class_num = class_num2ax\n",
        "        for i in range(len(nets)):\n",
        "            nets[i] = nets[i].to(device)\n",
        "        prob2 = test_one_image_three_nets_adaptive_shape(sub_imgs, data_shapes, label_shapes, data_shape2ax[-1],\n",
        "                                                         class_num, batch_size, nets,\n",
        "                                                         shape_mode=1)\n",
        "        pred2 = np.asarray(np.argmax(prob2, axis=3), np.uint16)\n",
        "        pred2 = pred2 * sub_weight\n",
        "    \n",
        "        # 5.3, test of 3rd network\n",
        "        if (pred2.sum() == 0):\n",
        "            [roid, roih, roiw] = sub_imgs[0].shape\n",
        "            bbox2 = [[0, 0, 0], [roid - 1, roih - 1, roiw - 1]]\n",
        "            subsub_imgs = sub_imgs\n",
        "            subsub_weight = sub_weight\n",
        "        else:\n",
        "            pred2_lc = ndimage.morphology.binary_closing(pred2, structure=struct)\n",
        "            pred2_lc = get_largest_two_component(pred2_lc)\n",
        "            bbox2 = get_ND_bounding_box(pred2_lc, margin)\n",
        "            subsub_imgs = [crop_ND_volume_with_bounding_box(one_img, bbox2[0], bbox2[1]) for one_img in sub_imgs]\n",
        "            subsub_weight = crop_ND_volume_with_bounding_box(sub_weight, bbox2[0], bbox2[1])\n",
        "    \n",
        "        if (config_net3):\n",
        "            data_shapes = [data_shape3[:-1], data_shape3[:-1], data_shape3[:-1]]\n",
        "            label_shapes = [label_shape3[:-1], label_shape3[:-1], label_shape3[:-1]]\n",
        "            nets = [net3, net3, net3]\n",
        "            #inputs = [x3, x3, x3]\n",
        "            class_num = class_num3\n",
        "        else:\n",
        "            data_shapes = [data_shape3ax[:-1], data_shape3sg[:-1], data_shape3cr[:-1]]\n",
        "            label_shapes = [label_shape3ax[:-1], label_shape3sg[:-1], label_shape3cr[:-1]]\n",
        "            nets = [net3ax, net3sg, net3cr]\n",
        "            #inputs = [x3ax, x3sg, x3cr]\n",
        "            class_num = class_num3ax\n",
        "        for i in range(len(nets)):\n",
        "            nets[i] = nets[i].to(device)\n",
        "        prob3 = test_one_image_three_nets_adaptive_shape(subsub_imgs, data_shapes, label_shapes, data_shape3ax[-1],\n",
        "                                                         class_num, batch_size, nets,\n",
        "                                                         shape_mode=1)\n",
        "    \n",
        "        pred3 = np.asarray(np.argmax(prob3, axis=3), np.uint16)\n",
        "        pred3 = pred3 * subsub_weight\n",
        "        # print(pred1, pred2, pred3)\n",
        "        # 5.4, fuse results at 3 levels\n",
        "        # convert subsub_label to full size (non-enhanced)\n",
        "        label3_roi = np.zeros_like(pred2)\n",
        "        label3_roi = set_ND_volume_roi_with_bounding_box_range(label3_roi, bbox2[0], bbox2[1], pred3)\n",
        "        label3 = np.zeros_like(pred1)\n",
        "        label3 = set_ND_volume_roi_with_bounding_box_range(label3, bbox1[0], bbox1[1], label3_roi)\n",
        "    \n",
        "        label2 = np.zeros_like(pred1)\n",
        "        label2 = set_ND_volume_roi_with_bounding_box_range(label2, bbox1[0], bbox1[1], pred2)\n",
        "    \n",
        "        label1_mask = (pred1 + label2 + label3) > 0\n",
        "        label1_mask = ndimage.morphology.binary_closing(label1_mask, structure=struct)\n",
        "        label1_mask = get_largest_two_component(label1_mask, False, wt_threshold)\n",
        "        label1 = pred1 * label1_mask\n",
        "    \n",
        "        label2_3_mask = (label2 + label3) > 0\n",
        "        label2_3_mask = label2_3_mask * label1_mask\n",
        "        label2_3_mask = ndimage.morphology.binary_closing(label2_3_mask, structure=struct)\n",
        "        label2_3_mask = remove_external_core(label1, label2_3_mask)\n",
        "        if (label2_3_mask.sum() > 0):\n",
        "            label2_3_mask = get_largest_two_component(label2_3_mask)\n",
        "        label1 = (label1 + label2_3_mask) > 0\n",
        "        label2 = label2_3_mask\n",
        "        label3 = label2 * label3\n",
        "        vox_3 = np.asarray(label3 > 0, np.float32).sum()\n",
        "        if (0 < vox_3 and vox_3 < 30):\n",
        "            label3 = np.zeros_like(label2)\n",
        "    \n",
        "        # 5.5, convert label and save output\n",
        "        out_label = label1 * 2\n",
        "        if ('Flair' in config_data['modality_postfix'] and 'mha' in config_data['file_postfix']):\n",
        "            out_label[label2 > 0] = 3\n",
        "            out_label[label3 == 1] = 1\n",
        "            out_label[label3 == 2] = 4\n",
        "        elif ('flair' in config_data['modality_postfix'] and 'nii' in config_data['file_postfix']):\n",
        "            out_label[label2 > 0] = 1\n",
        "            out_label[label3 > 0] = 4\n",
        "        out_label = np.asarray(out_label, np.int16)\n",
        "    # print(pred1.sum())\n",
        "    test_time.append(time.time() - t0)\n",
        "    final_label = np.zeros(temp_size, np.int16)\n",
        "    final_label = set_ND_volume_roi_with_bounding_box_range(final_label, temp_bbox[0], temp_bbox[1], out_label)\n",
        "    # print(final_label.shape)\n",
        "    save_array_as_nifty_volume(final_label, save_folder + \"/{0:}.nii.gz\".format(temp_name), img_names[0])\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data data_root /content/gdrive/MyDrive/csc490/brats2017/Brats17TrainingData /content/gdrive/MyDrive/csc490/brats2017/Brats17TrainingData\n",
            "data save_folder result17 result17\n",
            "data data_names config17/test_names.txt config17/test_names.txt\n",
            "data modality_postfix [flair, t1, t1ce, t2] ['flair', 't1', 't1ce', 't2']\n",
            "data file_postfix nii.gz nii.gz\n",
            "network1 net_type MSNet MSNet\n",
            "network1 net_name MSNet_1 MSNet_1\n",
            "network1 downsample_twice True True\n",
            "network1 data_shape [19, 180, 160, 4] [19, 180, 160, 4]\n",
            "network1 label_shape [11, 180, 160, 1] [11, 180, 160, 1]\n",
            "network1 class_num 2 2\n",
            "network1 model_file model17/msnet_wt32cr_4000.pt model17/msnet_wt32cr_4000.pt\n",
            "network1 model_save_prefix model17/msnet_wt32cr_4000 model17/msnet_wt32cr_4000\n",
            "network2 net_type MSNet MSNet\n",
            "network2 net_name MSNet_2 MSNet_2\n",
            "network2 downsample_twice True True\n",
            "network2 data_shape [19, 160, 180, 4] [19, 160, 180, 4]\n",
            "network2 label_shape [11, 160, 180, 1] [11, 160, 180, 1]\n",
            "network2 class_num 2 2\n",
            "network2 model_file model17/msnet_wt32cr_4000.pt model17/msnet_wt32cr_4000.pt\n",
            "network2 model_save_prefix model17/msnet_wt32cr_4000 model17/msnet_wt32cr_4000\n",
            "network3 net_type MSNet MSNet\n",
            "network3 net_name MSNet_3 MSNet_3\n",
            "network3 downsample_twice True True\n",
            "network3 data_shape [19, 160, 160, 4] [19, 160, 160, 4]\n",
            "network3 label_shape [11, 160, 160, 1] [11, 160, 160, 1]\n",
            "network3 class_num 2 2\n",
            "network3 model_file model17/msnet_wt32cr_4000.pt model17/msnet_wt32cr_4000.pt\n",
            "network3 model_save_prefix model17/msnet_wt32cr_4000 model17/msnet_wt32cr_4000\n",
            "testing test_slice_direction all all\n",
            "testing whole_tumor_only True True\n",
            ".\n",
            "\n",
            "Data load, 100.0% finished\n",
            "image_num 20\n",
            "======================\n",
            "======================\n",
            "142 186 143\n",
            "142 186 143\n",
            "143 142 186\n",
            "186 142 143\n",
            "======================\n",
            "======================\n",
            "143 176 157\n",
            "143 176 157\n",
            "157 143 176\n",
            "176 143 157\n",
            "======================\n",
            "======================\n",
            "147 179 151\n",
            "147 179 151\n",
            "151 147 179\n",
            "179 147 151\n",
            "======================\n",
            "======================\n",
            "149 180 148\n",
            "149 180 148\n",
            "148 149 180\n",
            "180 149 148\n",
            "======================\n",
            "======================\n",
            "145 163 148\n",
            "145 163 148\n",
            "148 145 163\n",
            "163 145 148\n",
            "======================\n",
            "======================\n",
            "145 164 154\n",
            "145 164 154\n",
            "154 145 164\n",
            "164 145 154\n",
            "======================\n",
            "======================\n",
            "140 182 146\n",
            "140 182 146\n",
            "146 140 182\n",
            "182 140 146\n",
            "======================\n",
            "======================\n",
            "148 182 139\n",
            "148 182 139\n",
            "139 148 182\n",
            "182 148 139\n",
            "======================\n",
            "======================\n",
            "142 185 151\n",
            "142 185 151\n",
            "151 142 185\n",
            "185 142 151\n",
            "======================\n",
            "======================\n",
            "151 182 141\n",
            "151 182 141\n",
            "141 151 182\n",
            "182 151 141\n",
            "======================\n",
            "======================\n",
            "135 175 151\n",
            "135 175 151\n",
            "151 135 175\n",
            "175 135 151\n",
            "======================\n",
            "======================\n",
            "144 172 145\n",
            "144 172 145\n",
            "145 144 172\n",
            "172 144 145\n",
            "======================\n",
            "======================\n",
            "147 170 143\n",
            "147 170 143\n",
            "143 147 170\n",
            "170 147 143\n",
            "======================\n",
            "======================\n",
            "143 192 155\n",
            "143 192 155\n",
            "155 143 192\n",
            "192 143 155\n",
            "======================\n",
            "======================\n",
            "137 169 136\n",
            "137 169 136\n",
            "136 137 169\n",
            "169 137 136\n",
            "======================\n",
            "======================\n",
            "147 172 147\n",
            "147 172 147\n",
            "147 147 172\n",
            "172 147 147\n",
            "======================\n",
            "======================\n",
            "144 174 142\n",
            "144 174 142\n",
            "142 144 174\n",
            "174 144 142\n",
            "======================\n",
            "======================\n",
            "143 177 143\n",
            "143 177 143\n",
            "143 143 177\n",
            "177 143 143\n",
            "======================\n",
            "======================\n",
            "148 170 144\n",
            "148 170 144\n",
            "144 148 170\n",
            "170 148 144\n",
            "======================\n",
            "======================\n",
            "146 180 147\n",
            "146 180 147\n",
            "147 146 180\n",
            "180 146 147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NNOhj3PNCSk",
        "outputId": "c69abf29-ee82-4e4d-f1fe-7be033c21911"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from __future__ import absolute_import, print_function\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('./')\n",
        "import numpy as np\n",
        "from util.data_process import load_3d_volume_as_array, binary_dice3d\n",
        "\n",
        "def get_ground_truth_names(g_folder, patient_names_file):\n",
        "    with open(patient_names_file) as f:\n",
        "            content = f.readlines()\n",
        "            patient_names = [x.strip() for x in content]\n",
        "    full_gt_names = []\n",
        "    for patient_name in patient_names:\n",
        "        patient_dir = os.path.join(g_folder, patient_name)\n",
        "        img_names   = os.listdir(patient_dir)\n",
        "        gt_name = None\n",
        "        for img_name in img_names:\n",
        "          \n",
        "              if 'seg.' in img_name:\n",
        "                  gt_name = img_name\n",
        "                  break\n",
        "        gt_name = os.path.join(patient_dir, gt_name)\n",
        "        full_gt_names.append(gt_name)\n",
        "    return full_gt_names\n",
        "\n",
        "def get_segmentation_names(seg_folder, patient_names_file):\n",
        "    with open(patient_names_file) as f:\n",
        "            content = f.readlines()\n",
        "            patient_names = [x.strip() for x in content]\n",
        "    full_seg_names = []\n",
        "    for patient_name in patient_names:\n",
        "        seg_name = os.path.join(seg_folder, patient_name + '.nii.gz')\n",
        "        full_seg_names.append(seg_name)\n",
        "    return full_seg_names\n",
        "\n",
        "def dice_of_brats_data_set(gt_names, seg_names, type_idx):\n",
        "    assert(len(gt_names) == len(seg_names))\n",
        "    dice_all_data = []\n",
        "    for i in range(len(gt_names)):\n",
        "        g_volume = load_3d_volume_as_array(gt_names[i])\n",
        "        s_volume = load_3d_volume_as_array(seg_names[i])\n",
        "\n",
        "        dice_one_volume = []\n",
        "        if(type_idx ==0): # whole tumor\n",
        "            temp_dice = binary_dice3d(s_volume > 0, g_volume > 0)\n",
        "            dice_one_volume = [temp_dice]\n",
        "        elif(type_idx == 1): # tumor core\n",
        "            seg_=np.copy(s_volume)\n",
        "            ground_=np.copy(g_volume)\n",
        "            seg_[seg_==2]=0\n",
        "            ground_[ground_==2]=0\n",
        "            temp_dice = binary_dice3d(seg_ > 0, ground_ > 0)\n",
        "            dice_one_volume = [temp_dice]\n",
        "        else: #enhenced tumor\n",
        "            temp_dice = binary_dice3d(s_volume ==4, g_volume ==4)\n",
        "            dice_one_volume = [temp_dice]\n",
        "            \n",
        "        dice_all_data.append(dice_one_volume)\n",
        "    return dice_all_data\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    \n",
        "\n",
        "    s_folder = 'result17'\n",
        "    g_folder = '/content/gdrive/MyDrive/csc490/brats2017/Brats17TrainingData'\n",
        "    patient_names_file = 'config17/test_names.txt'\n",
        "\n",
        "    print(\"=\"*15,\"Segmenting\",\"=\"*15)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*15,\"Evaluating\",\"=\"*15)\n",
        "    test_types = ['whole','core', 'enhenced']\n",
        "    gt_names  = get_ground_truth_names(g_folder, patient_names_file)\n",
        "    seg_names = get_segmentation_names(s_folder, patient_names_file)\n",
        "    for type_idx in range(3):\n",
        "        dice = dice_of_brats_data_set(gt_names, seg_names, type_idx)\n",
        "        dice = np.asarray(dice)\n",
        "        dice_mean = dice.mean(axis = 0)\n",
        "        dice_std  = dice.std(axis  = 0)\n",
        "        test_type = test_types[type_idx]\n",
        "        np.savetxt(s_folder + '/dice_{0:}.txt'.format(test_type), dice)\n",
        "        np.savetxt(s_folder + '/dice_{0:}_mean.txt'.format(test_type), dice_mean)\n",
        "        np.savetxt(s_folder + '/dice_{0:}_std.txt'.format(test_type), dice_std)\n",
        "        print('tissue type', test_type)\n",
        "        print('dice mean  ', dice_mean)\n",
        "        print('dice std   ', dice_std)\n",
        " \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Segmenting ===============\n",
            "=============== Evaluating ===============\n",
            "tissue type whole\n",
            "dice mean   [0.83166942]\n",
            "dice std    [0.13862527]\n",
            "tissue type core\n",
            "dice mean   [0.55896184]\n",
            "dice std    [0.17798024]\n",
            "tissue type enhenced\n",
            "dice mean   [0.25]\n",
            "dice std    [0.4330127]\n"
          ]
        }
      ]
    }
  ]
}