{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC490_Evaluation_Clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K19HB997HXF2",
        "outputId": "b9f43164-2a64-4377-d005-315d75e8f14c"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "MOUNTPOINT = '/content/gdrive'\n",
        "drive.mount(MOUNTPOINT)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rierl482pKB7",
        "outputId": "f173049d-496e-4853-9bcb-cef92fa1af73"
      },
      "source": [
        "!git clone https://github.com/Angeloschert/CSC490_Braindon.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSC490_Braindon'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (365/365), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 365 (delta 215), reused 252 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (365/365), 12.50 MiB | 1.33 MiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Y9Z7xEIaeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e3ba3c-ce6f-4163-b354-084e5baff501"
      },
      "source": [
        "!pip install numpy scipy torch nibabel simpleITK crfseg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Collecting simpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting crfseg\n",
            "  Downloading crfseg-1.0.0.tar.gz (6.9 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from crfseg) (0.11.1+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->crfseg) (7.1.2)\n",
            "Building wheels for collected packages: crfseg\n",
            "  Building wheel for crfseg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crfseg: filename=crfseg-1.0.0-py3-none-any.whl size=8409 sha256=8f48154b0e05724abaeecde2cecd2f84d1894bb7b26c1754699d086f0b3abb4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/31/37/3a44ed00971454bddb0fb9096019e5c6822fa4364679cb8493\n",
            "Successfully built crfseg\n",
            "Installing collected packages: simpleITK, crfseg\n",
            "Successfully installed crfseg-1.0.0 simpleITK-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-5ngdCXpah4"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/CSC490_Braindon/')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4yMcXC_Q0Bq"
      },
      "source": [
        "!rm -rf result17\n",
        "!mkdir result17\n",
        "!mkdir result17/HGG\n",
        "!mkdir result17/LGG"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utSPFoVRx5ON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "0cffd870-de38-47ad-f8c8-411ee01b41dd"
      },
      "source": [
        "gdrive/MyDrive/Schools/CSC490/BRATS2017/Brats17TrainingData\n",
        "CSC490_Braindon/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-9e4e0ae9cd6f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    CSC490_Braindon/\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWt88sJBYtQE"
      },
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "from util.train_test_func import *\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from crfseg import CRF\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from util.data_loader import *\n",
        "from util.data_process import *\n",
        "from util.parse_config import parse_config\n",
        "from util.train_test_func import *\n",
        "from util.MSNet import MSNet\n",
        "from util.data_process import load_3d_volume_as_array, binary_dice3d\n",
        "\n",
        "sys.path.append('./')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcn3RVaK71On"
      },
      "source": [
        "def evaluate(config_file, crf=True):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    configs = load_configs(config_file)\n",
        "    config_test = configs[\"config_test\"]\n",
        "    batch_size = configs[\"batch_size\"]\n",
        "\n",
        "    net1, net1ax, net1sg, net1cr, class_num1, class_num1_ax, class_num1_sg, class_num1_cr, data_shape1, data_shape1_ax, data_shape1_sg, data_shape1_cr, label_shape1, label_shape1_ax, label_shape1_sg, label_shape1_cr = load_network(device, configs, \"config_net1\", 'network1ax', 'network1sg', 'network1cr', batch_size)\n",
        "    net2, net2ax, net2sg, net2cr, class_num2, class_num2_ax, class_num2_sg, class_num2_cr, data_shape2, data_shape2_ax, data_shape2_sg, data_shape2_cr, label_shape2, label_shape2_ax, label_shape2_sg, label_shape2_cr = None, None, None, None, 0, 0, 0, 0, None, None, None, None, None, None, None, None\n",
        "    net3, net3ax, net3sg, net3cr, class_num3, class_num3_ax, class_num3_sg, class_num3_cr, data_shape3, data_shape3_ax, data_shape3_sg, data_shape3_cr, label_shape3, label_shape3_ax, label_shape3_sg, label_shape3_cr = None, None, None, None, 0, 0, 0, 0, None, None, None, None, None, None, None, None\n",
        "\n",
        "    if (config_test.get('whole_tumor_only', False) is False):\n",
        "        net2, net2ax, net2sg, net2cr, class_num2, class_num2_ax, class_num2_sg, class_num2_cr, data_shape2, data_shape2_ax, data_shape2_sg, data_shape2_cr, label_shape2, label_shape2_ax, label_shape2_sg, label_shape2_cr = load_network(device, configs, \"config_net2\", 'network2ax', 'network2sg', 'network2cr', batch_size)\n",
        "        net3, net3ax, net3sg, net3cr, class_num3, class_num3_ax, class_num3_sg, class_num3_cr, data_shape3, data_shape3_ax, data_shape3_sg, data_shape3_cr, label_shape3, label_shape3_ax, label_shape3_sg, label_shape3_cr = load_network(device, configs, \"config_net3\", 'network3ax', 'network3sg', 'network3cr', batch_size)\n",
        "    \n",
        "    print(os.curdir)\n",
        "    config_data = configs[\"config_data\"]\n",
        "    dataloader = DataLoader(config_data)\n",
        "    dataloader.load_data()\n",
        "    image_num = dataloader.get_total_image_number()\n",
        "\n",
        "    # 3, start to test\n",
        "    test_slice_direction = config_test.get('test_slice_direction', 'all')\n",
        "    save_folder = config_data['save_folder']\n",
        "    test_time = []\n",
        "    struct = ndimage.generate_binary_structure(3, 2)\n",
        "    margin = config_test.get('roi_patch_margin', 5)\n",
        "    print(\"image_num\",image_num)\n",
        "\n",
        "    final_labels = []\n",
        "    for i in range(image_num):\n",
        "        [temp_imgs, temp_weight, temp_name, img_names, temp_bbox, temp_size] = dataloader.get_image_data_with_name(i)\n",
        "\n",
        "        print(\"temp imgs: \" + str(np.array(temp_imgs).shape))\n",
        "        print(\"temp weight: \" + str(temp_weight.shape))\n",
        "        print(\"temp name: \" + str(temp_name))\n",
        "        print(\"image names: \" + str(img_names))\n",
        "        print(\"temp bbox: \" + str(temp_bbox))\n",
        "        print(\"temp size: \" + str(temp_size))\n",
        "\n",
        "        t0 = time.time()\n",
        "        pred1 = test1(device, crf, batch_size, temp_imgs, temp_weight, temp_name, img_names,\n",
        "                     temp_bbox, temp_size, net1, net1ax, net1sg, net1cr,\n",
        "                     class_num1, class_num1_ax, class_num1_sg, class_num1_cr,\n",
        "                     data_shape1, data_shape1_ax, data_shape1_sg, data_shape1_cr, \n",
        "                     label_shape1, label_shape1_ax, label_shape1_sg, label_shape1_cr, 1)\n",
        "\n",
        "        wt_threshold = 2000\n",
        "        if (config_test.get('whole_tumor_only', False) is True):\n",
        "            pred1_lc = ndimage.morphology.binary_closing(pred1, structure=struct)\n",
        "            print(\"pred1_lc right after morphology.binary_closing: \" + str(pred1_lc.shape))\n",
        "\n",
        "            pred1_lc = get_largest_two_component(pred1_lc, False, wt_threshold)\n",
        "            print(\"pred1_lc right after get_largest_two_component: \" + str(pred1_lc.shape))\n",
        "\n",
        "            out_label = pred1_lc\n",
        "            print(\"out_label: \" + str(out_label.shape))\n",
        "        else:\n",
        "            print(\"Not whole tumor\")\n",
        "            pred2, bbox1 = test2(device, crf, pred1, struct, batch_size, temp_imgs,\n",
        "                                 temp_weight, temp_name, img_names, temp_bbox,\n",
        "                                 temp_size, net2, net2ax, net2sg, net2cr,\n",
        "                                 class_num2, class_num2_ax, class_num2_sg,\n",
        "                                 class_num2_cr, data_shape2, data_shape2_ax,\n",
        "                                 data_shape2_sg, data_shape2_cr, label_shape2,\n",
        "                                 label_shape2_ax, label_shape2_sg,\n",
        "                                 label_shape2_cr, 2)\n",
        "            \n",
        "            pred2, bbox2 = test3(device, crf, pred2, struct, batch_size, temp_imgs,\n",
        "                                 temp_weight, temp_name, img_names, temp_bbox,\n",
        "                                 temp_size, net3, net3ax, net3sg, net3cr,\n",
        "                                 class_num3, class_num3_ax, class_num3_sg,\n",
        "                                 class_num3_cr, data_shape3, data_shape3_ax,\n",
        "                                 data_shape3_sg, data_shape3_cr, label_shape3,\n",
        "                                 label_shape3_ax, label_shape3_sg,\n",
        "                                 label_shape3_cr, 3)\n",
        "            \n",
        "            out_label = fuse(pred1, pred2, pred3, bbox1, bbox2)\n",
        "            print(\"out_label: \" + str(out_label.shape))\n",
        "        \n",
        "        # print(pred.sum())\n",
        "        test_time.append(time.time() - t0)\n",
        "        final_label = np.zeros(temp_size, np.int16)\n",
        "        final_label = set_ND_volume_roi_with_bounding_box_range(final_label, temp_bbox[0], temp_bbox[1], out_label)\n",
        "        final_labels.append((temp_name, final_label))\n",
        "        print(\"final_label: \" + str(final_label.shape))\n",
        "        print(\"\\n\")\n",
        "\n",
        "        save_array_as_nifty_volume(final_label, save_folder + \"/{0:}.nii.gz\".format(temp_name), img_names[0])\n",
        "\n",
        "    return final_labels\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gN4YQIkDRJp"
      },
      "source": [
        "# Model generating factory\n",
        "\n",
        "class NetFactory(object):\n",
        "    @staticmethod\n",
        "    def create(name):\n",
        "        if name == 'MSNet':\n",
        "            return MSNet\n",
        "        # add your own networks here\n",
        "        print('unsupported network:', name)\n",
        "        exit()\n",
        "\n",
        "class CRFactory(object):\n",
        "    @staticmethod\n",
        "    def create(name):\n",
        "        if name == 'gaussian_crf':\n",
        "            crf_model = nn.Sequential(\n",
        "                nn.Identity(),\n",
        "                CRF(n_spatial_dims=3)\n",
        "            )\n",
        "            return crf_model\n",
        "        # add your own networks here\n",
        "        print('unsupported network:', name)\n",
        "        exit()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP8Lh2235kHt"
      },
      "source": [
        "# utils\n",
        "def expand_n_channels(batch_size, n_channel, final_label):\n",
        "    spatial = tuple(final_label.shape)\n",
        "    result = np.zeros((batch_size, n_channel) + final_label.shape)\n",
        "    for i in range(batch_size):\n",
        "        for j in range(n_channel):\n",
        "            result[i, j, :, :] = final_label\n",
        "    return result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TRlP0Z4bwZS"
      },
      "source": [
        "config_file = 'CSC490_Braindon/config17/test_wt.txt'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Oy_zySxILq"
      },
      "source": [
        "# 1, load configure file\n",
        "def load_configs(config_file):\n",
        "    config = parse_config(config_file)\n",
        "    config_data = config.get('data')\n",
        "    config_net1 = config.get('network1', None)\n",
        "    config_net2 = config.get('network2', None)\n",
        "    config_net3 = config.get('network3', None)\n",
        "    config_test = config.get('testing')\n",
        "    batch_size = config_test.get('batch_size', 5)\n",
        "\n",
        "    configs = {\n",
        "        \"config\": config,\n",
        "        \"config_data\": config_data,\n",
        "        \"config_net1\": config_net1,\n",
        "        \"config_net2\": config_net2,\n",
        "        \"config_net3\": config_net3,\n",
        "        \"config_test\": config_test,\n",
        "        \"batch_size\": batch_size\n",
        "    }\n",
        "\n",
        "    return configs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4MXzZcrxG4S"
      },
      "source": [
        "# 2, network for whole tumor, tumor core and enhanced tumor core\n",
        "def load_network(device, configs, net_name, net_ax_name, net_sg_name, net_cr_name, batch_size):\n",
        "    config = configs[\"config\"]\n",
        "    config_net = configs[net_name]\n",
        "\n",
        "    net = net_ax = net_sg = net_cr = None\n",
        "    class_num = class_num_ax = class_num_sg = class_num_cr = 0\n",
        "    data_shape = data_shape_ax = data_shape_sg = data_shape_cr = None\n",
        "    label_shape = label_shape_ax = label_shape_sg = label_shape_cr = None\n",
        "    \n",
        "    if (config_net):\n",
        "        print(\"Has net{}\".format(net_name[-1]))\n",
        "        net_type = config_net['net_type']\n",
        "        net_name = config_net['net_name']\n",
        "        data_shape = config_net['data_shape']\n",
        "        label_shape = config_net['label_shape']\n",
        "        class_num = config_net['class_num']\n",
        "        model_save_prefix = \"CSC490_Braindon/\" + config_net['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        # construct graph for network\n",
        "        full_data_shape = [batch_size] + data_shape\n",
        "        \n",
        "        net_class = NetFactory.create(net_type)\n",
        "        net = net_class(num_classes=class_num, w_reg=None,\n",
        "                        b_reg=None, in_chns=full_data_shape[-1])\n",
        "        net.load_state_dict(torch.load(model_save_prefix, map_location=device)[\"model_state_dict\"])\n",
        "    else:\n",
        "        print(\"No net{}\".format(net_name[-1]))\n",
        "        config_net_ax = config[net_ax_name]\n",
        "        config_net_sg = config[net_sg_name]\n",
        "        config_net_cr = config[net_cr_name]\n",
        "\n",
        "        # construct graph for network axial\n",
        "        net_type_ax = config_net_ax['net_type']\n",
        "        net_name_ax = config_net_ax['net_name']\n",
        "        data_shape_ax = config_net_ax['data_shape']\n",
        "        label_shape_ax = config_net_ax['label_shape']\n",
        "        class_num_ax = config_net_ax['class_num']\n",
        "        model_save_prefix_ax = config_net_ax['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape_ax = [batch_size] + data_shape_ax\n",
        "        net_class_ax = NetFactory.create(net_type_ax)\n",
        "        net_ax = net_class_ax(num_classes=class_num_ax, w_reg=None,\n",
        "                            b_reg=None, in_chns=full_data_shape_ax[-1])\n",
        "        net_ax.load_state_dict(torch.load(model_save_prefix_ax, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "        # construct graph for network sagittal\n",
        "        net_type_sg = config_net_sg['net_type']\n",
        "        net_name_sg = config_net_sg['net_name']\n",
        "        data_shape_sg = config_net_sg['data_shape']\n",
        "        label_shape_sg = config_net_sg['label_shape']\n",
        "        class_num_sg = config_net_sg['class_num']\n",
        "        model_save_prefix_sg = config_net_sg['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape_sg = [batch_size] + data_shape_sg\n",
        "        net_class_sg = NetFactory.create(net_type_sg)\n",
        "        net_sg = net_class_sg(num_classes=class_num_sg, w_reg=None,\n",
        "                            b_reg=None, in_chns=full_data_shape_sg[-1])\n",
        "        net_sg.load_state_dict(torch.load(model_save_prefix_sg, map_location=device)[\"model_state_dict\"])\n",
        "\n",
        "        # construct graph for network corogal\n",
        "        net_type_cr = config_net_cr['net_type']\n",
        "        net_name_cr = config_net_cr['net_name']\n",
        "        data_shape_cr = config_net_cr['data_shape']\n",
        "        label_shape_cr = config_net_cr['label_shape']\n",
        "        class_num_cr = config_net_cr['class_num']\n",
        "        model_save_prefix_cr = config_net_cr['model_save_prefix'] + \".pt\"\n",
        "\n",
        "        full_data_shape_cr = [batch_size] + data_shape_cr\n",
        "        net_class_cr = NetFactory.create(net_type_cr)\n",
        "        net_cr = net_class_cr(num_classes=class_num_cr, w_reg=None,\n",
        "                            b_reg=None, in_chns=full_data_shape_cr[-1])\n",
        "        net_cr.load_state_dict(torch.load(model_save_prefix_cr, map_location=device)[\"model_state_dict\"])\n",
        "    return [net, net_ax, net_sg, net_cr, class_num, class_num_ax, class_num_sg,\n",
        "            class_num_cr, data_shape, data_shape_ax, data_shape_sg,\n",
        "            data_shape_cr, label_shape, label_shape_ax,\n",
        "            label_shape_sg, label_shape_cr]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ag1ZaQWQj06"
      },
      "source": [
        "def test1(device, crf, batch_size, temp_imgs, temp_weight, temp_name, img_names, temp_bbox,\n",
        "          temp_size, net, net_ax, net_sg, net_cr, class_num, class_num_ax,\n",
        "          class_num_sg, class_num_cr, data_shape, data_shape_ax, data_shape_sg,\n",
        "          data_shape_cr, label_shape, label_shape_ax, label_shape_sg,\n",
        "          label_shape_cr, netid):\n",
        "# ================================== test of 1st network ==================================\n",
        "    if (net):\n",
        "        data_shapes = [data_shape[:-1], data_shape[:-1], data_shape[:-1]]\n",
        "        label_shapes = [label_shape[:-1], label_shape[:-1], label_shape[:-1]]\n",
        "        nets = [net, net, net]\n",
        "        #inputs = [x1, x1, x1]\n",
        "    else:\n",
        "        data_shapes = [data_shape_ax[:-1], data_shape_sg[:-1], data_shape_cr[:-1]]\n",
        "        data_shape = data_shape_ax[-1]\n",
        "        label_shapes = [label_shape_ax[:-1], label_shape_sg[:-1], label_shape_cr[:-1]]\n",
        "        nets = [net_ax, net_sg, net_cr]\n",
        "        #inputs = [x1ax, x1sg, x1cr]\n",
        "        class_num = class_num_ax\n",
        "    for i in range(len(nets)):\n",
        "        nets[i] = nets[i].to(device)\n",
        "    # print('=' * 20, \"Going to prediction\")\n",
        "    prob = test_one_image_three_nets_adaptive_shape(temp_imgs, data_shapes, label_shapes, data_shape[-1],\n",
        "                                                     class_num, batch_size, nets, shape_mode=2)\n",
        "    print(\"prob{} size: \".format(netid) + str(prob.shape))\n",
        "\n",
        "    # ================== CRF ==================================\n",
        "    if crf:\n",
        "        crf_model = CRFactory.create(\"gaussian_crf\")\n",
        "        d, h, w, c = prob.shape\n",
        "        prob = prob.reshape(c, d, h, w)\n",
        "        prob = np.expand_dims(prob, axis=0)\n",
        "        prob = crf_model(torch.tensor(prob, dtype=torch.float32))\n",
        "        print(\"prob size after crf: \".format(netid) + str(prob.shape))\n",
        "\n",
        "        prob = prob.detach().numpy()[0].reshape(d, h, w, c)\n",
        "    # ===========================================================\n",
        "    pred = np.asarray(np.argmax(prob, axis=3), np.uint16)\n",
        "    pred = pred * temp_weight\n",
        "    print(\"pred{} size\".format(netid) + str(pred.shape))\n",
        "    # ================================== End of 1st network ==================================\n",
        "    return pred\n",
        "\n",
        "\n",
        "def test2(device, crf, pred, struct, batch_size, temp_imgs, temp_weight, temp_name,\n",
        "           img_names, temp_bbox, temp_size, net, net_ax, net_sg, net_cr,\n",
        "           class_num, class_num_ax, class_num_sg, class_num_cr, data_shape,\n",
        "           data_shape_ax, data_shape_sg, data_shape_cr, label_shape,\n",
        "           label_shape_ax, label_shape_sg, label_shape_cr, netid):\n",
        "    # ================================== test of 2nd network ==================================\n",
        "    if (pred.sum() == 0):\n",
        "        print('net{} output is null'.format(netid), temp_name)\n",
        "        bbox = get_ND_bounding_box(temp_imgs[0] > 0, margin)\n",
        "    else:\n",
        "        pred_lc = ndimage.morphology.binary_closing(pred, structure=struct)\n",
        "        pred_lc = get_largest_two_component(pred_lc, False, wt_threshold)\n",
        "        bbox = get_ND_bounding_box(pred_lc, margin)\n",
        "    sub_imgs = [crop_ND_volume_with_bounding_box(one_img, bbox[0], bbox[1]) for one_img in temp_imgs]\n",
        "    sub_weight = crop_ND_volume_with_bounding_box(temp_weight, bbox[0], bbox[1])\n",
        "\n",
        "    if (net):\n",
        "        data_shapes = [data_shape[:-1], data_shape[:-1], data_shape[:-1]]\n",
        "        label_shapes = [label_shape[:-1], label_shape[:-1], label_shape[:-1]]\n",
        "        nets = [net, net, net]\n",
        "        #inputs = [x2, x2, x2]\n",
        "    else:\n",
        "        data_shapes = [data_shape_ax[:-1], data_shape_sg[:-1], data_shape_cr[:-1]]\n",
        "        label_shapes = [label_shape_ax[:-1], label_shape_sg[:-1], label_shape_cr[:-1]]\n",
        "        nets = [net_ax, net_sg, net_cr]\n",
        "        #inputs = [x2ax, x2sg, x2cr]\n",
        "        class_num = class_num_ax\n",
        "    for i in range(len(nets)):\n",
        "        nets[i] = nets[i].to(device)\n",
        "    prob = test_one_image_three_nets_adaptive_shape(sub_imgs, data_shapes, label_shapes, data_shape[-1],\n",
        "                                                        class_num, batch_size, nets, shape_mode=1)\n",
        "    print(\"prob{} size: \".format(netid) + str(prob.shape).format(netid))\n",
        "    \n",
        "    # ================== CRF ==================================\n",
        "    if crf:\n",
        "        crf_model = CRFactory.create(\"gaussian_crf\")\n",
        "        d, h, w, c = prob.shape\n",
        "        prob = prob.reshape(c, d, h, w)\n",
        "        prob = np.expand_dims(prob, axis=0)\n",
        "        prob = crf_model(torch.tensor(prob, dtype=torch.float32))\n",
        "        print(\"prob{} size after crf: \".format(netid) + str(prob.shape))\n",
        "\n",
        "        prob = prob.detach().numpy()[0].reshape(d, h, w, c)\n",
        "    # ===========================================================\n",
        "    pred = np.asarray(np.argmax(prob, axis=3), np.uint16)\n",
        "    pred = pred * sub_weight\n",
        "    print(\"pred{} size: \".format(netid) + str(pred.shape))\n",
        "    # ================================== End of 2nd network ==================================\n",
        "    return pred, bbox\n",
        "\n",
        "\n",
        "def test3(device, crf, pred, struct, batch_size, temp_imgs, temp_weight, temp_name,\n",
        "           img_names, temp_bbox, temp_size, net, net_ax, net_sg, net_cr,\n",
        "           class_num, class_num_ax, class_num_sg, class_num_cr, data_shape,\n",
        "           data_shape_ax, data_shape_sg, data_shape_cr, label_shape,\n",
        "           label_shape_ax, label_shape_sg, label_shape_cr, netid):\n",
        "    # ================================== test of 3rd network ==================================\n",
        "    if (pred2.sum() == 0):\n",
        "        [roid, roih, roiw] = sub_imgs[0].shape\n",
        "        bbox = [[0, 0, 0], [roid - 1, roih - 1, roiw - 1]]\n",
        "        subsub_imgs = sub_imgs\n",
        "        subsub_weight = sub_weight\n",
        "    else:\n",
        "        pred_lc = ndimage.morphology.binary_closing(pred, structure=struct)\n",
        "        pred_lc = get_largest_two_component(pred_lc)\n",
        "        bbox = get_ND_bounding_box(pred_lc, margin)\n",
        "        subsub_imgs = [crop_ND_volume_with_bounding_box(one_img, bbox[0], bbox[1]) for one_img in sub_imgs]\n",
        "        subsub_weight = crop_ND_volume_with_bounding_box(sub_weight, bbox[0], bbox[1])\n",
        "\n",
        "    if (net):\n",
        "        data_shapes = [data_shape[:-1], data_shape[:-1], data_shape[:-1]]\n",
        "        label_shapes = [label_shape[:-1], label_shape[:-1], label_shape[:-1]]\n",
        "        nets = [net, net, net]\n",
        "        #inputs = [x3, x3, x3]\n",
        "    else:\n",
        "        data_shapes = [data_shape_ax[:-1], data_shape_sg[:-1], data_shape_cr[:-1]]\n",
        "        label_shapes = [label_shape_ax[:-1], label_shape_sg[:-1], label_shape_cr[:-1]]\n",
        "        nets = [net_ax, net_sg, net_cr]\n",
        "        #inputs = [x3ax, x3sg, x3cr]\n",
        "        class_num = class_num_ax\n",
        "    for i in range(len(nets)):\n",
        "        nets[i] = nets[i].to(device)\n",
        "    prob = test_one_image_three_nets_adaptive_shape(sub_imgs, data_shapes, label_shapes, data_shape[-1],\n",
        "                                                        class_num, batch_size, nets, shape_mode=1)\n",
        "    print(\"prob{} size: \".format(netid) + str(prob.shape).format(netid))\n",
        "    \n",
        "    # ================== CRF ==================================\n",
        "    if crf:\n",
        "        crf_model = CRFactory.create(\"gaussian_crf\")\n",
        "        d, h, w, c = prob.shape\n",
        "        prob = prob.reshape(c, d, h, w)\n",
        "        prob = np.expand_dims(prob, axis=0)\n",
        "        prob = crf_model(torch.tensor(prob, dtype=torch.float32))\n",
        "        print(\"prob{} size after crf: \".format(netid) + str(prob.shape))\n",
        "\n",
        "        prob = prob.detach().numpy()[0].reshape(d, h, w, c)\n",
        "    # ===========================================================\n",
        "    pred = np.asarray(np.argmax(prob, axis=3), np.uint16)\n",
        "    pred = pred * sub_weight\n",
        "    print(\"pred{} size: \".format(netid) + str(pred.shape))\n",
        "    # ================================== End of 3rd network ==================================\n",
        "    return pred, bbox\n",
        "\n",
        "\n",
        "def fuse(pred1, pred2, pred3, bbox1, bbox2):\n",
        "    # 5.4, fuse results at 3 levels\n",
        "    # convert subsub_label to full size (non-enhanced)\n",
        "    label3_roi = np.zeros_like(pred2)\n",
        "    label3_roi = set_ND_volume_roi_with_bounding_box_range(label3_roi, bbox2[0], bbox2[1], pred3)\n",
        "    label3 = np.zeros_like(pred1)\n",
        "    label3 = set_ND_volume_roi_with_bounding_box_range(label3, bbox1[0], bbox1[1], label3_roi)\n",
        "\n",
        "    label2 = np.zeros_like(pred1)\n",
        "    label2 = set_ND_volume_roi_with_bounding_box_range(label2, bbox1[0], bbox1[1], pred2)\n",
        "\n",
        "    label1_mask = (pred1 + label2 + label3) > 0\n",
        "    label1_mask = ndimage.morphology.binary_closing(label1_mask, structure=struct)\n",
        "    label1_mask = get_largest_two_component(label1_mask, False, wt_threshold)\n",
        "    label1 = pred1 * label1_mask\n",
        "\n",
        "    label2_3_mask = (label2 + label3) > 0\n",
        "    label2_3_mask = label2_3_mask * label1_mask\n",
        "    label2_3_mask = ndimage.morphology.binary_closing(label2_3_mask, structure=struct)\n",
        "    label2_3_mask = remove_external_core(label1, label2_3_mask)\n",
        "\n",
        "    if (label2_3_mask.sum() > 0):\n",
        "        label2_3_mask = get_largest_two_component(label2_3_mask)\n",
        "\n",
        "    label1 = (label1 + label2_3_mask) > 0\n",
        "    label2 = label2_3_mask\n",
        "    label3 = label2 * label3\n",
        "    vox_3 = np.asarray(label3 > 0, np.float32).sum()\n",
        "\n",
        "    if (0 < vox_3 and vox_3 < 30):\n",
        "        label3 = np.zeros_like(label2)\n",
        "\n",
        "    # 5.5, convert label and save output\n",
        "    out_label = label1 * 2\n",
        "    if ('Flair' in config_data['modality_postfix'] and 'mha' in config_data['file_postfix']):\n",
        "        out_label[label2 > 0] = 3\n",
        "        out_label[label3 == 1] = 1\n",
        "        out_label[label3 == 2] = 4\n",
        "    elif ('flair' in config_data['modality_postfix'] and 'nii' in config_data['file_postfix']):\n",
        "        out_label[label2 > 0] = 1\n",
        "        out_label[label3 > 0] = 4\n",
        "    out_label = np.asarray(out_label, np.int16)\n",
        "    \n",
        "    return out_label\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NNOhj3PNCSk"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "def get_ground_truth_names(g_folder, patient_names_file):\n",
        "    with open(patient_names_file) as f:\n",
        "        content = f.readlines()\n",
        "        patient_names = [x.strip() for x in content]\n",
        "        print(patient_names)\n",
        "    full_gt_names = []\n",
        "    for patient_name in patient_names:\n",
        "        patient_dir = os.path.join(g_folder, patient_name)\n",
        "        img_names   = os.listdir(patient_dir)\n",
        "        gt_name = None\n",
        "        for img_name in img_names:\n",
        "            if 'seg.' in img_name:\n",
        "                gt_name = img_name\n",
        "                break\n",
        "        gt_name = os.path.join(patient_dir, gt_name)\n",
        "        full_gt_names.append(gt_name)\n",
        "    return full_gt_names\n",
        "\n",
        "def get_segmentation_names(seg_folder, patient_names_file):\n",
        "    with open(patient_names_file) as f:\n",
        "        content = f.readlines()\n",
        "        patient_names = [x.strip() for x in content]\n",
        "    full_seg_names = []\n",
        "    for patient_name in patient_names:\n",
        "        seg_name = os.path.join(seg_folder, patient_name + '.nii.gz')\n",
        "        full_seg_names.append(seg_name)\n",
        "    return full_seg_names\n",
        "\n",
        "def dice_of_brats_data_set(gt_names, seg_names, type_idx):\n",
        "    assert(len(gt_names) == len(seg_names))\n",
        "    dice_all_data = []\n",
        "    for i in range(len(gt_names)):\n",
        "        g_volume = load_3d_volume_as_array(gt_names[i])\n",
        "        s_volume = load_3d_volume_as_array(seg_names[i])\n",
        "\n",
        "        dice_one_volume = []\n",
        "        if(type_idx ==0): # whole tumor\n",
        "            temp_dice = binary_dice3d(s_volume > 0, g_volume > 0)\n",
        "            dice_one_volume = [temp_dice]\n",
        "        elif(type_idx == 1): # tumor core\n",
        "            seg_=np.copy(s_volume)\n",
        "            ground_=np.copy(g_volume)\n",
        "            seg_[seg_==2]=0\n",
        "            ground_[ground_==2]=0\n",
        "            temp_dice = binary_dice3d(seg_ > 0, ground_ > 0)\n",
        "            dice_one_volume = [temp_dice]\n",
        "        else: #enhenced tumor\n",
        "            temp_dice = binary_dice3d(s_volume ==4, g_volume ==4)\n",
        "            dice_one_volume = [temp_dice]\n",
        "            \n",
        "        dice_all_data.append(dice_one_volume)\n",
        "    return dice_all_data\n",
        " \n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3gAherHZYzR",
        "outputId": "0ae8addc-9182-492f-ca7f-9c3b6d0bc363"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # test_wt.txt:\n",
        "    # data_root         = gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
        "    # save_folder       = result17\n",
        "    # data_names        = CSC490_Braindon/config17/test_names_temp.txt\n",
        "\n",
        "    # test_names_temp:\n",
        "    # HGG/Brats17_CBICA_ATX_1\n",
        "    # HGG/Brats17_CBICA_AXN_1\n",
        "\n",
        "    s_folder = 'result17'\n",
        "\n",
        "    # g_folder = 'gdrive/MyDrive/Schools/CSC490/BRATS2017/Brats17TrainingData'\n",
        "    g_folder = 'gdrive/MyDrive/BRATS2017/Brats17TrainingData'\n",
        "    \n",
        "    # patient_names_file = 'CSC490_Braindon/config17/test_names.txt'\n",
        "    patient_names_file = 'CSC490_Braindon/config17/test_names_temp.txt'\n",
        "\n",
        "    print(os.getcwd())\n",
        "\n",
        "    print(\"Using CRF\")\n",
        "    print(\"=\"*15,\"Segmenting\",\"=\"*15)\n",
        "    evaluate(config_file, True)\n",
        "    print(\"=\"*15,\"Evaluating\",\"=\"*15)\n",
        "\n",
        "    test_types = ['whole','core', 'enhenced']\n",
        "    gt_names  = get_ground_truth_names(g_folder, patient_names_file)\n",
        "    seg_names = get_segmentation_names(s_folder, patient_names_file)\n",
        "    for type_idx in range(3):\n",
        "        dice = dice_of_brats_data_set(gt_names, seg_names, type_idx)\n",
        "        dice = np.asarray(dice)\n",
        "        dice_mean = dice.mean(axis = 0)\n",
        "        dice_std  = dice.std(axis  = 0)\n",
        "        test_type = test_types[type_idx]\n",
        "        np.savetxt(s_folder + '/dice_{0:}.txt'.format(test_type), dice)\n",
        "        np.savetxt(s_folder + '/dice_{0:}_mean.txt'.format(test_type), dice_mean)\n",
        "        np.savetxt(s_folder + '/dice_{0:}_std.txt'.format(test_type), dice_std)\n",
        "        print('tissue type', test_type)\n",
        "        print('dice mean  ', dice_mean)\n",
        "        print('dice std   ', dice_std)\n",
        "    \n",
        "    print(\"Disabling CRF\")\n",
        "    print(\"=\"*15,\"Segmenting\",\"=\"*15)\n",
        "    evaluate(config_file, False)\n",
        "    print(\"=\"*15,\"Evaluating\",\"=\"*15)\n",
        "\n",
        "    test_types = ['whole','core', 'enhenced']\n",
        "    gt_names  = get_ground_truth_names(g_folder, patient_names_file)\n",
        "    seg_names = get_segmentation_names(s_folder, patient_names_file)\n",
        "    for type_idx in range(3):\n",
        "        dice = dice_of_brats_data_set(gt_names, seg_names, type_idx)\n",
        "        dice = np.asarray(dice)\n",
        "        dice_mean = dice.mean(axis = 0)\n",
        "        dice_std  = dice.std(axis  = 0)\n",
        "        test_type = test_types[type_idx]\n",
        "        np.savetxt(s_folder + '/dice_{0:}.txt'.format(test_type), dice)\n",
        "        np.savetxt(s_folder + '/dice_{0:}_mean.txt'.format(test_type), dice_mean)\n",
        "        np.savetxt(s_folder + '/dice_{0:}_std.txt'.format(test_type), dice_std)\n",
        "        print('tissue type', test_type)\n",
        "        print('dice mean  ', dice_mean)\n",
        "        print('dice std   ', dice_std)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Using CRF\n",
            "=============== Segmenting ===============\n",
            "data data_root gdrive/MyDrive/BRATS2017/Brats17TrainingData gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
            "data save_folder result17 result17\n",
            "data data_names CSC490_Braindon/config17/test_names_temp.txt CSC490_Braindon/config17/test_names_temp.txt\n",
            "data modality_postfix [flair, t1, t1ce, t2] ['flair', 't1', 't1ce', 't2']\n",
            "data file_postfix nii.gz nii.gz\n",
            "network1 net_type MSNet MSNet\n",
            "network1 net_name MSNet_1 MSNet_1\n",
            "network1 downsample_twice True True\n",
            "network1 data_shape [19, 180, 160, 4] [19, 180, 160, 4]\n",
            "network1 label_shape [11, 180, 160, 1] [11, 180, 160, 1]\n",
            "network1 class_num 2 2\n",
            "network1 model_file model17/msnet_1_300.pt model17/msnet_1_300.pt\n",
            "network1 model_save_prefix model17/msnet_1_300 model17/msnet_1_300\n",
            "network2 net_type MSNet MSNet\n",
            "network2 net_name MSNet_2 MSNet_2\n",
            "network2 downsample_twice True True\n",
            "network2 data_shape [19, 160, 180, 4] [19, 160, 180, 4]\n",
            "network2 label_shape [11, 160, 180, 1] [11, 160, 180, 1]\n",
            "network2 class_num 2 2\n",
            "network2 model_file model17/msnet_2_300.pt model17/msnet_2_300.pt\n",
            "network2 model_save_prefix model17/msnet_2_300 model17/msnet_2_300\n",
            "network3 net_type MSNet MSNet\n",
            "network3 net_name MSNet_3 MSNet_3\n",
            "network3 downsample_twice True True\n",
            "network3 data_shape [19, 160, 160, 4] [19, 160, 160, 4]\n",
            "network3 label_shape [11, 160, 160, 1] [11, 160, 160, 1]\n",
            "network3 class_num 2 2\n",
            "network3 model_file model17/msnet_3_300.pt model17/msnet_3_300.pt\n",
            "network3 model_save_prefix model17/msnet_3_300 model17/msnet_3_300\n",
            "testing test_slice_direction all all\n",
            "testing whole_tumor_only True True\n",
            "Has net1\n",
            ".\n",
            "\n",
            "Data load, 100.0% finished\n",
            "image_num 2\n",
            "temp imgs: (4, 142, 186, 143)\n",
            "temp weight: (142, 186, 143)\n",
            "temp name: HGG/Brats17_CBICA_ATX_1\n",
            "image names: ['gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_flair.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_t1.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_t1ce.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_t2.nii.gz']\n",
            "temp bbox: [[0, 35, 47], [141, 220, 189]]\n",
            "temp size: (155, 240, 240)\n",
            "======================\n",
            "======================\n",
            "142 186 143\n",
            "142 186 143\n",
            "143 142 186\n",
            "186 142 143\n",
            "prob1 size: (142, 186, 143, 2)\n",
            "prob size after crf: torch.Size([1, 2, 142, 186, 143])\n",
            "pred1 size(142, 186, 143)\n",
            "pred1_lc right after morphology.binary_closing: (142, 186, 143)\n",
            "pred1_lc right after get_largest_two_component: (142, 186, 143)\n",
            "out_label: (142, 186, 143)\n",
            "final_label: (155, 240, 240)\n",
            "\n",
            "\n",
            "temp imgs: (4, 143, 176, 157)\n",
            "temp weight: (143, 176, 157)\n",
            "temp name: HGG/Brats17_CBICA_AXN_1\n",
            "image names: ['gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_flair.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_t1.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_t1ce.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_t2.nii.gz']\n",
            "temp bbox: [[0, 43, 40], [142, 218, 196]]\n",
            "temp size: (155, 240, 240)\n",
            "======================\n",
            "======================\n",
            "143 176 157\n",
            "143 176 157\n",
            "157 143 176\n",
            "176 143 157\n",
            "prob1 size: (143, 176, 157, 2)\n",
            "prob size after crf: torch.Size([1, 2, 143, 176, 157])\n",
            "pred1 size(143, 176, 157)\n",
            "pred1_lc right after morphology.binary_closing: (143, 176, 157)\n",
            "pred1_lc right after get_largest_two_component: (143, 176, 157)\n",
            "out_label: (143, 176, 157)\n",
            "final_label: (155, 240, 240)\n",
            "\n",
            "\n",
            "=============== Evaluating ===============\n",
            "['HGG/Brats17_CBICA_ATX_1', 'HGG/Brats17_CBICA_AXN_1']\n",
            "gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
            "gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
            "tissue type whole\n",
            "dice mean   [0.59034495]\n",
            "dice std    [0.34225324]\n",
            "tissue type core\n",
            "dice mean   [0.52648093]\n",
            "dice std    [0.23187434]\n",
            "tissue type enhenced\n",
            "dice mean   [9.87724075e-15]\n",
            "dice std    [5.43200604e-15]\n",
            "Disabling CRF\n",
            "=============== Segmenting ===============\n",
            "data data_root gdrive/MyDrive/BRATS2017/Brats17TrainingData gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
            "data save_folder result17 result17\n",
            "data data_names CSC490_Braindon/config17/test_names_temp.txt CSC490_Braindon/config17/test_names_temp.txt\n",
            "data modality_postfix [flair, t1, t1ce, t2] ['flair', 't1', 't1ce', 't2']\n",
            "data file_postfix nii.gz nii.gz\n",
            "network1 net_type MSNet MSNet\n",
            "network1 net_name MSNet_1 MSNet_1\n",
            "network1 downsample_twice True True\n",
            "network1 data_shape [19, 180, 160, 4] [19, 180, 160, 4]\n",
            "network1 label_shape [11, 180, 160, 1] [11, 180, 160, 1]\n",
            "network1 class_num 2 2\n",
            "network1 model_file model17/msnet_1_300.pt model17/msnet_1_300.pt\n",
            "network1 model_save_prefix model17/msnet_1_300 model17/msnet_1_300\n",
            "network2 net_type MSNet MSNet\n",
            "network2 net_name MSNet_2 MSNet_2\n",
            "network2 downsample_twice True True\n",
            "network2 data_shape [19, 160, 180, 4] [19, 160, 180, 4]\n",
            "network2 label_shape [11, 160, 180, 1] [11, 160, 180, 1]\n",
            "network2 class_num 2 2\n",
            "network2 model_file model17/msnet_2_300.pt model17/msnet_2_300.pt\n",
            "network2 model_save_prefix model17/msnet_2_300 model17/msnet_2_300\n",
            "network3 net_type MSNet MSNet\n",
            "network3 net_name MSNet_3 MSNet_3\n",
            "network3 downsample_twice True True\n",
            "network3 data_shape [19, 160, 160, 4] [19, 160, 160, 4]\n",
            "network3 label_shape [11, 160, 160, 1] [11, 160, 160, 1]\n",
            "network3 class_num 2 2\n",
            "network3 model_file model17/msnet_3_300.pt model17/msnet_3_300.pt\n",
            "network3 model_save_prefix model17/msnet_3_300 model17/msnet_3_300\n",
            "testing test_slice_direction all all\n",
            "testing whole_tumor_only True True\n",
            "Has net1\n",
            ".\n",
            "\n",
            "Data load, 100.0% finished\n",
            "image_num 2\n",
            "temp imgs: (4, 142, 186, 143)\n",
            "temp weight: (142, 186, 143)\n",
            "temp name: HGG/Brats17_CBICA_ATX_1\n",
            "image names: ['gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_flair.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_t1.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_t1ce.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_ATX_1/Brats17_CBICA_ATX_1_t2.nii.gz']\n",
            "temp bbox: [[0, 35, 47], [141, 220, 189]]\n",
            "temp size: (155, 240, 240)\n",
            "======================\n",
            "======================\n",
            "142 186 143\n",
            "142 186 143\n",
            "143 142 186\n",
            "186 142 143\n",
            "prob1 size: (142, 186, 143, 2)\n",
            "pred1 size(142, 186, 143)\n",
            "pred1_lc right after morphology.binary_closing: (142, 186, 143)\n",
            "pred1_lc right after get_largest_two_component: (142, 186, 143)\n",
            "out_label: (142, 186, 143)\n",
            "final_label: (155, 240, 240)\n",
            "\n",
            "\n",
            "temp imgs: (4, 143, 176, 157)\n",
            "temp weight: (143, 176, 157)\n",
            "temp name: HGG/Brats17_CBICA_AXN_1\n",
            "image names: ['gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_flair.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_t1.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_t1ce.nii.gz', 'gdrive/MyDrive/BRATS2017/Brats17TrainingData/HGG/Brats17_CBICA_AXN_1/Brats17_CBICA_AXN_1_t2.nii.gz']\n",
            "temp bbox: [[0, 43, 40], [142, 218, 196]]\n",
            "temp size: (155, 240, 240)\n",
            "======================\n",
            "======================\n",
            "143 176 157\n",
            "143 176 157\n",
            "157 143 176\n",
            "176 143 157\n",
            "prob1 size: (143, 176, 157, 2)\n",
            "pred1 size(143, 176, 157)\n",
            "pred1_lc right after morphology.binary_closing: (143, 176, 157)\n",
            "pred1_lc right after get_largest_two_component: (143, 176, 157)\n",
            "out_label: (143, 176, 157)\n",
            "final_label: (155, 240, 240)\n",
            "\n",
            "\n",
            "=============== Evaluating ===============\n",
            "['HGG/Brats17_CBICA_ATX_1', 'HGG/Brats17_CBICA_AXN_1']\n",
            "gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
            "gdrive/MyDrive/BRATS2017/Brats17TrainingData\n",
            "tissue type whole\n",
            "dice mean   [0.56719053]\n",
            "dice std    [0.36971406]\n",
            "tissue type core\n",
            "dice mean   [0.54341215]\n",
            "dice std    [0.23683966]\n",
            "tissue type enhenced\n",
            "dice mean   [9.87724075e-15]\n",
            "dice std    [5.43200604e-15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "CfiCLyoQUub9",
        "outputId": "d78652c9-6828-49ef-b510-d12e1784e814"
      },
      "source": [
        "while True:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-648a2bab0435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWyu5xhqVQRo",
        "outputId": "55c14a9c-cd01-419e-93ba-6ec30d9f1d67"
      },
      "source": [
        "!zip -r /content/result17_no_crf.zip /content/result17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/result17/ (stored 0%)\n",
            "  adding: content/result17/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/result17/dice_whole_std.txt (stored 0%)\n",
            "  adding: content/result17/HGG/ (stored 0%)\n",
            "  adding: content/result17/HGG/Brats17_2013_25_1.nii.gz (deflated 77%)\n",
            "  adding: content/result17/HGG/Brats17_CBICA_AXN_1.nii.gz (deflated 63%)\n",
            "  adding: content/result17/HGG/Brats17_CBICA_ATX_1.nii.gz (deflated 74%)\n",
            "  adding: content/result17/HGG/Brats17_TCIA_135_1.nii.gz (deflated 52%)\n",
            "  adding: content/result17/HGG/Brats17_TCIA_491_1.nii.gz (deflated 56%)\n",
            "  adding: content/result17/HGG/Brats17_CBICA_AQN_1.nii.gz (deflated 69%)\n",
            "  adding: content/result17/HGG/Brats17_TCIA_151_1.nii.gz (deflated 52%)\n",
            "  adding: content/result17/HGG/Brats17_TCIA_396_1.nii.gz (deflated 63%)\n",
            "  adding: content/result17/HGG/Brats17_CBICA_AOZ_1.nii.gz (deflated 74%)\n",
            "  adding: content/result17/HGG/Brats17_TCIA_603_1.nii.gz (deflated 66%)\n",
            "  adding: content/result17/dice_enhenced_std.txt (stored 0%)\n",
            "  adding: content/result17/dice_core_mean.txt (stored 0%)\n",
            "  adding: content/result17/dice_whole_mean.txt (stored 0%)\n",
            "  adding: content/result17/LGG/ (stored 0%)\n",
            "  adding: content/result17/LGG/Brats17_2013_29_1.nii.gz (deflated 76%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_310_1.nii.gz (deflated 98%)\n",
            "  adding: content/result17/LGG/Brats17_2013_24_1.nii.gz (deflated 81%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_490_1.nii.gz (deflated 54%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_634_1.nii.gz (deflated 75%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_630_1.nii.gz (deflated 78%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_449_1.nii.gz (deflated 59%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_620_1.nii.gz (deflated 74%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_152_1.nii.gz (deflated 69%)\n",
            "  adding: content/result17/LGG/Brats17_TCIA_346_1.nii.gz (deflated 80%)\n",
            "  adding: content/result17/dice_whole.txt (deflated 51%)\n",
            "  adding: content/result17/dice_core_std.txt (stored 0%)\n",
            "  adding: content/result17/dice_core.txt (deflated 49%)\n",
            "  adding: content/result17/dice_enhenced_mean.txt (stored 0%)\n",
            "  adding: content/result17/dice_enhenced.txt (deflated 55%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Uvkv07r5VwDu",
        "outputId": "a3279df4-bea7-4ace-d2d1-588af8459c5e"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/result17_no_crf.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bdcc878b-71d5-4aa4-b584-a0fbfc037427\", \"result17_no_crf.zip\", 169526)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}