{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62366551-4e67-4023-bd44-fa498c553378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e27f0af-38f5-4738-9537-5be3a665dad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1888e2b-06b1-4f82-ab35-61bc964ab8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_chns, out_chns, kernels=[[1, 3, 3], [1, 3, 3]], strides=[[1,1,1], [1,1,1]], dilation_rate=[[1,1,1], [1,1,1]], activation=nn.PReLU, w_init=None, w_reg=None, res=True):\n",
    "        super().__init__()\n",
    "        self.in_chns = in_chns\n",
    "        self.out_chns = out_chns\n",
    "        self.kernels = kernels\n",
    "        self.strides = strides\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.activation = activation\n",
    "        self.w_init = w_init\n",
    "        self.w_reg = w_reg\n",
    "        self.res = res\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = x\n",
    "        for i in range(len(self.kernels)):\n",
    "            kernel, stride, dilation = self.kernels[i], self.strides[i], self.dilation_rate[i]\n",
    "            self.block = nn.Sequential(\n",
    "                nn.BatchNorm2d(self.out_chns),\n",
    "                activation(),\n",
    "                nn.Conv2d(self.in_chns, out_channels=self.out_chns, kernel_size=kernel, stride=self.strides, dilation=dilation)\n",
    "            )\n",
    "            output = self.block(x)\n",
    "        if self.res:\n",
    "            output += x\n",
    "        return x\n",
    "    \n",
    "            \n",
    "            \n",
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self,in_chns, out_chns, kernels, padding, strides=[1, 1, 1], activation=nn.PReLU, w_init=None, w_reg=None, b_init=None, b_reg=None, with_bn=True, deconv=False):\n",
    "        super().__init__()\n",
    "        self.in_chns = in_chns\n",
    "        self.out_chns = out_chns\n",
    "        self.kernels = kernels\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.w_init = w_init\n",
    "        self.w_reg = w_reg\n",
    "        self.b_init = b_init\n",
    "        self.b_reg = b_reg\n",
    "        if not deconv:\n",
    "            self.conv_block = nn.Conv2d(in_chns, out_chns, kernel_size=kernels, padding=padding, stride=strid, bias=True)\n",
    "        else:\n",
    "            self.conv_block = nn.ConvTranspose2d(in_chns, out_chns, kernel_size=kernels, padding=padding, stride=strid, bias=True)\n",
    "            \n",
    "        if with_bn:\n",
    "            self.bn = nn.BatchNorm2d(self.out_chns)\n",
    "        else:\n",
    "            self.bn = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.conv_block(x)\n",
    "        output = self.bn(x)\n",
    "        output = self.activation(x)\n",
    "        return output\n",
    "    \n",
    "class SliceLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, margin=1):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Fix this\n",
    "        return x[:, 1:-(2 * self.margin), :]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aff9f03-6e99-4840-948b-13348d181a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSNet(nn.Module):\n",
    "    def __init__(self, in_chns, num_classes, w_init=None, w_reg=None, b_init=None, b_reg=None, activation=nn.PReLU):\n",
    "        # TODO: Add weight init\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.w_init, self.w_reg, self.b_init, self.b_reg = w_init, w_reg, b_init, b_reg\n",
    "        self.activation = activation\n",
    "        self.base_chns = [32, 32, 32, 32]\n",
    "        self.is_WTNet = True\n",
    "        \n",
    "        # First Block\n",
    "        self.block1 = nn.Sequential(\n",
    "            ResBlock(in_chns, self.base_chns[0], activation=activation, w_init=w_init, w_reg=w_reg),\n",
    "            ResBlock(self.base_chns[0], self.base_chns[0], activation=activation, w_init=w_init, w_reg=w_reg)\n",
    "        )\n",
    "        self.fuse1 = Conv2dBlock(self.base_chns[0], self.base_chns[0], kernels=[3, 1, 1], padding='valid', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.downsample1 = Conv2dBlock(self.base_chns[0], self.base_chns[0], kernels=[1,3,3],strides=[1,2,2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.feature_expand1 = Conv2dBlock(self.base_chns[0], self.base_chns[1], kernels=[1,1,1],strides=[1,1,1], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        \n",
    "        #Second Block\n",
    "        self.block2 = nn.Sequential(\n",
    "            ResBlock(self.base_chns[1], self.base_chns[1], activation=activation, w_init=w_init, w_reg=w_reg),\n",
    "            ResBlock(self.base_chns[1], self.base_chns[1], activation=activation, w_init=w_init, w_reg=w_reg)\n",
    "        )\n",
    "        self.fuse2 = Conv2dBlock(self.base_chns[1], self.base_chns[1], kernels=[3, 1, 1], padding='valid', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.downsample2 = Conv2dBlock(self.base_chns[1], self.base_chns[1], kernels=[1,3,3],strides=[1,2,2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.feature_expand2 = Conv2dBlock(self.base_chns[1], self.base_chns[2], kernels=[1,1,1],strides=[1,1,1], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.pred_1E = nn.Conv2d(self.base_chns[1], self.num_classes, kernel_size=[1, 3, 3], padding='same')\n",
    "        self.pred_1WT = Conv2dBlock(self.base_chns[1], self.num_classes, kernels=[1, 3, 3], strides=[1, 2, 2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg, deconv=True)\n",
    "        \n",
    "        #Third Block\n",
    "        self.block3 = nn.Sequential(\n",
    "            ResBlock(self.base_chns[2], self.base_chns[2], strides=[[1,1,1], [1,1,1]], activation=activation, w_init=w_init, w_reg=w_reg),\n",
    "            ResBlock(self.base_chns[2], self.base_chns[2], strides=[[1,2,2], [1,2,2]], activation=activation, w_init=w_init, w_reg=w_reg),\n",
    "            ResBlock(self.base_chns[2], self.base_chns[2], strides=[[1,3,3], [1,3,3]], activation=activation, w_init=w_init, w_reg=w_reg)\n",
    "        )\n",
    "        self.fuse3 = Conv2dBlock(self.base_chns[2], self.base_chns[2], kernels=[3, 1, 1], padding='valid', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.feature_expand3 = Conv2dBlock(self.base_chns[2], self.base_chns[3], kernels=[1,1,1],strides=[1,1,1], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.pred_21 = Conv2dBlock(self.base_chns[2], self.num_classes * 2, kernels=[1, 3, 3], strides=[1, 2, 2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg, deconv=True)\n",
    "        self.pred_22 = Conv2dBlock(self.base_chns[2], self.num_classes * 2, kernels=[1, 3, 3], strides=[1, 2, 2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg, deconv=True)\n",
    "        \n",
    "        #Fourth Block\n",
    "        self.block4 = nn.Sequential(\n",
    "            ResBlock(self.base_chns[3], self.base_chns[3], strides=[[1,3,3], [1,3,3]], activation=activation, w_init=w_init, w_reg=w_reg),\n",
    "            ResBlock(self.base_chns[3], self.base_chns[3], strides=[[1,2,2], [1,2,2]], activation=activation, w_init=w_init, w_reg=w_reg),\n",
    "            ResBlock(self.base_chns[3], self.base_chns[3], strides=[[1,1,1], [1,1,1]], activation=activation, w_init=w_init, w_reg=w_reg)\n",
    "        )\n",
    "        self.fuse4 = Conv2dBlock(self.base_chns[3], self.base_chns[3], kernels=[3, 1, 1], padding='valid', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg)\n",
    "        self.pred_31 = Conv2dBlock(self.base_chns[3], self.num_classes * 2, kernels=[1, 3, 3], strides=[1, 2, 2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg, deconv=True)\n",
    "        self.pred_32 = Conv2dBlock(self.base_chns[3], self.num_classes * 2, kernels=[1, 3, 3], strides=[1, 2, 2], padding='same', activation=self.activation, w_init=self.w_init, w_reg=self.w_reg, b_init=self.b_init, b_reg=self.b_reg, deconv=True)\n",
    "        \n",
    "        #TODO: Change this MAYBE\n",
    "        self.final_pred = nn.Conv2d(self.base_chns[3], self.num_classes, kernel_size=[1,3,3], padding='same')\n",
    "        self.centra_slice1 = SliceLayer(margin = 2)\n",
    "        self.centra_slice2 = SliceLayer(margin = 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        f1 = x\n",
    "        f1 = self.block1(f1)\n",
    "        f1 = self.fuse1(f1)\n",
    "        if self.is_WTNet:\n",
    "            f1 = self.downsample1(f1)\n",
    "        if self.base_chns[0] != self.base_chns[1]:\n",
    "            f1 = self.feature_expand1(f1)\n",
    "        f1 = self.block2(f1)\n",
    "        f1 = self.fuse2(f1)\n",
    "        \n",
    "        f2 = self.downsample2(f1)\n",
    "        if self.base_chns[1] != self.base_chns[2]:\n",
    "            f2 = self.feature_expand1(f2)\n",
    "        f2 = self.block3(f2)\n",
    "        f2 = self.fuse3(f2)\n",
    "        \n",
    "        f3 = f2\n",
    "        if self.base_chns[2] != self.base_chns[3]:\n",
    "            f3 = self.feature_expand1(f3)\n",
    "        f3 = self.block4(f3)\n",
    "        f3 = self.fuse3(f3)\n",
    "        \n",
    "        # Prediction\n",
    "        p1 = centra_slice1(f1)\n",
    "        if self.is_WTNet:\n",
    "            p1 = self.pred_1WT(p1)\n",
    "        else:\n",
    "            p1 = self.pred_1E(p1)\n",
    "        \n",
    "        p2 = self.centra_slice2(f2)\n",
    "        p2 = self.pred_21(p2)\n",
    "        if self.is_WTNet:\n",
    "            p2 = self.pred_22(p2)\n",
    "            \n",
    "        p3 = self.pred_31(p3)\n",
    "        if self.is_WTNet:\n",
    "            p3 = self.pred_32(p3)\n",
    "        \n",
    "        combine = torch.cat([p1, p2, p3], dim=4)\n",
    "        return self.final_pred(cat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe8203-7125-4590-9f31-e6f99fcd6591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
